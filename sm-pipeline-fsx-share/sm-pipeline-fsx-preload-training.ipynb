{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bec8e5-17a1-43e5-bf24-9a9494aa91e2",
   "metadata": {},
   "source": [
    "# SageMaker Pipeline Pre-load data onto FSx and training\n",
    "\n",
    "*(This notebook was tested with the \"Python 3 (PyTorch 1.8 CPU Optimized)\" kernel.)*\n",
    "\n",
    "Amazon SageMaker Pipelines provides ML developers and MLOps engineers configurable ability to orchestrate SageMaker jobs. The definition of the pipeline orchestration can be exported as a JSON object which represents domain acyclic graph (DAG). Amazon SageMaker provides the ability to integrate with Amazon FSx for Lustre to speed up the training jobs. Amazon FSx for Lustre can be linked to S3 and will automatically synchronize the files. Upon linking with S3, FSx copies files from S3 on-demand basis as they are accessed. Copy includes any file that is not in Fsx locally or if the source has changed since the last copy.  However, after the first epoch files should be fully copied and subsequent epochs should be faster (Assuming one epoch sweeps through the entire training dataset). After the training is done, the files are persistent in FSx and not removed automatically. Also as long as the files in S3 have not changed, ay subsequent runs will not copy the files from S3 to FSx. \n",
    "\n",
    "One of the options to reduce the cost is to pre-load the files onto Fsx and initiate this from a cheaper instance before starting the training job.  This page provides details. https://docs.aws.amazon.com/fsx/latest/LustreGuide/preload-file-contents-hsm-dra.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78a91ef6-09f6-446c-98e2-c1b81aaf8aaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook illustrates how SageMaker training can be initiated with FSx storage using Pipelines and trigger preload of the files. In this notebook, we use Amazon SageMaker to train a convolutional neural network using PyTorch and the CIFAR-10 dataset, and then run SageMaker Batch transform on the trained model.\n",
    "\n",
    "The steps in this pipeline include:\n",
    "* Pre load data into FSx file system\n",
    "* Train a Pytorch Model with the files preloaded\n",
    "* Persist the trained model\n",
    "* Batch Transform using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bde1a-2be0-4b6c-8e44-3f5961d1b9d6",
   "metadata": {},
   "source": [
    "<img src=\"images/SM-Pipelines-FSx-Preload.png\" alt=\"FSx Selection configuration\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887cd7a-0a88-46bb-9f21-90c4413f595e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-requisities setup\n",
    "\n",
    "Following steps need to done as a prequisite before you proceed with the rest of the steps in the notebook. \n",
    "\n",
    "1) Create an S3 bucket that will store the training data and Batch transform input and output\n",
    "2) Create a VPC , subnet or leverage an existing VPC, Subnet and Security Group. \n",
    "3) Create FSx for Lustre that will be synced with the S3 bucket. This file system will be hosted in VPC and Subnet and security group will be associated with FSx file system's network interface \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c1d410c-2602-4fcf-bba3-6b4692930296",
   "metadata": {},
   "source": [
    "<img src=\"images/fsx-select.png\" alt=\"FSx Selection configuration\" style=\"width: 500px;\"/>\n",
    "<br>\n",
    "<img src=\"images/fsx-network.png\" alt=\"FSx Network configuration\" style=\"width: 500px;\"/>\n",
    "<br>\n",
    "<img src=\"images/fsx-datarepo.png\" alt=\"FSx Data repo configuration\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb2399-5816-4fad-b289-750e6d9601d3",
   "metadata": {},
   "source": [
    "\n",
    "Once the file system is created, get the File system Id and File system mount name from the details page. This will be used to do associate the preloader and training jobs.\n",
    "\n",
    "\n",
    "<img src=\"images/fsx-details.png\" alt=\"FSx Details\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a40a4-b125-4960-a8a2-d904f21bb30a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Specify the following items after the pre-requisites setp is complate.\n",
    "\n",
    "- VPC Subnets\n",
    "- Security Group Id\n",
    "- An Amazon S3 bucket and prefix for training and model data. This should be in the same region used for SageMaker Studio, training, and hosting.\n",
    "\n",
    "In the below section enter FSX configuration details and S3 bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59569a5-cb35-4483-aa74-ed4271484754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Network configuration details here\n",
    "security_group_ids = #['sg-aaa','sg-bbb']\n",
    "subnets = #['subnet-'] \n",
    "\n",
    "# Specify FSx Lustre file system id.\n",
    "file_system_id = #'fs-'\n",
    "file_system_mount_name = #'aabbcc'\n",
    "file_system_path = #'/fsx'\n",
    "\n",
    "\n",
    "# Specify directory path for input data on the file system. \n",
    "# You need to provide normalized and absolute path below.\n",
    "file_system_directory_path = f'/{file_system_mount_name}{file_system_path}/data'\n",
    "print(f'FSx file-system data input path: {file_system_directory_path}')\n",
    "\n",
    "s3_bucket  = #'s3_bucket_name'\n",
    "print(f'S3 bucket {s3_bucket}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b1473-6455-401d-ad11-732af4f6f210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbfd3d-9f57-43f4-97e9-72947086307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.inputs import FileSystemInput, TrainingInput, TransformInput\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, CacheConfig,TransformStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "\n",
    "from cifar_utils import classes, show_img, train_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06634aea-a2ef-462f-9260-f7b20a64de9e",
   "metadata": {},
   "source": [
    "### Session\n",
    "Let's start by specifying:\n",
    "- SageMaker session, Pipeline session, region and account Id\n",
    "- An IAM role for SageMaker to access to your training and model data. If you wish to use a different role than the one set up for SageMaker Studio, replace `sagemaker.get_execution_role()` with the appropriate IAM role or ARN. For more about using IAM roles with SageMaker, see [the AWS documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85386d07-5e20-4c3a-b43d-aa951baa2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Session objects, region and account ID\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "pipeline_session = PipelineSession()\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = sagemaker_session.account_id()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f\"SageMaker Execution Role:{role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e2e4d-f624-4647-be87-030bb3afb5d7",
   "metadata": {},
   "source": [
    "### Create a custom Docker image\n",
    "Below section creates a custom docker image. This will be used as a training image and will preload the files into FSx. We will use sagemaker studio image build to build the image and upload the image to ECR.\n",
    "\n",
    "NOTE: If you have already built the image and published to ECR, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210d2b0-80d7-42f3-95f2-79f3fc75d0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fe2ff-9c3a-4ebb-a51a-ae7fd37d06c3",
   "metadata": {},
   "source": [
    "Create the preloader script. This will be used as the entrypoint in custom docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf773b-52b5-48ad-8d19-238bb1125054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile container/preload-fsx.sh\n",
    "\n",
    "ls /opt/ml/input/data/train/\n",
    "echo \"Starting preload with hsm_restore....\"\n",
    "nohup find /opt/ml/input/data/train/ -type f -print0 | xargs -0 -n 1 lfs hsm_restore\n",
    "echo \"Preload is complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449811df-9273-4c30-8abb-a382ac6d75d7",
   "metadata": {},
   "source": [
    "Create the DockerFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03909b35-1580-42ec-a4e3-9e25436c1af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile container/Dockerfile\n",
    "\n",
    "FROM amazonlinux:2\n",
    "\n",
    "MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
    "\n",
    "RUN amazon-linux-extras install -y lustre\n",
    "\n",
    "# Set up the entrypoint\n",
    "COPY preload-fsx.sh /opt/preload-fsx.sh\n",
    "\n",
    "ENTRYPOINT /opt/preload-fsx.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b724f-b1af-4180-b149-05580fca78c2",
   "metadata": {},
   "source": [
    "Trigger the docker build using SageMaker studio sm-docker utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee4ea3-54ce-4228-86ac-a269c029d2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x preload-fsx.sh\n",
    "\n",
    "sm-docker build .  --repository fsx-demo-preload:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e48588-452f-4a41-ab30-0ae997759050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preloader_image = '{}.dkr.ecr.{}.amazonaws.com/fsx-demo-preload:latest'.format(account_id, region)\n",
    "image_dir = \"data/images\"\n",
    "inference_prefix = \"batch_transform\"\n",
    "inference_inputs = f\"s3://{s3_bucket}/{inference_prefix}\"\n",
    "inreference_output = f\"s3://{s3_bucket}/BatchTransformOutput\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abecfed-0eea-4be7-bf18-df67ef33af0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare training Data\n",
    "\n",
    "In this section we will import training data images and upload to S3. We will use CIFAR-10 dataset to train a CNN model. The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is a subset of the [80 million tiny images dataset](https://people.csail.mit.edu/torralba/tinyimages). It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class.\n",
    "\n",
    "Below steps download CIFAR images and uploads to S3\n",
    "\n",
    "NOTE: If you have already imported the images and uploaded to S3, you can skip this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e846e9-941b-4788-91dd-7ff12e1361cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = train_data_loader()\n",
    "test_loader = test_data_loader()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "show_img(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(\" \".join(\"%9s\" % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "prefix = \"pytorch-cnn-cifar10-example\"\n",
    "inputs = S3Uploader.upload(\"data\", \"s3://{}/{}/data\".format(s3_bucket, prefix))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "for i in range(100):\n",
    "    images, labels = dataiter.next()\n",
    "    for j in range(len(images)):\n",
    "        torchvision.utils.save_image(tensor=images[j],fp=f\"{image_dir}/{i}-{j}.png\",format=\"png\")\n",
    "        \n",
    "inference_inputs = sagemaker_session.upload_data(\n",
    "    path=image_dir, bucket=s3_bucket, key_prefix=inference_prefix\n",
    ")\n",
    "print(\"Input S3 path for batch inference: {}\".format(inference_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eba0ac-8267-4c1d-873a-1ea16a195b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup SM pipeline parameters and File system inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81022c07-03a5-4a4c-a35e-011fbc39741f",
   "metadata": {},
   "source": [
    "In this section we will create a FileSystemInput and a channel with the input. This will be passed to the Estimator fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f1d31-efe6-4a09-9a00-7bc2485b6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_system_access_mode = 'ro'\n",
    "file_system_type = 'FSxLustre'\n",
    "\n",
    "train = FileSystemInput(file_system_id=file_system_id,\n",
    "                                    file_system_type=file_system_type,\n",
    "                                    directory_path=file_system_directory_path,\n",
    "                                    file_system_access_mode=file_system_access_mode)\n",
    "\n",
    "data_channels = {'train': train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc308936-916d-4f04-aed3-155bd772fc7d",
   "metadata": {},
   "source": [
    "In the below section, you can configure the instances for \n",
    "* Preloader \n",
    "* Training instances \n",
    "* Batch inference instances in the below section. \n",
    "You can select different types of instances for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466379c-42be-4d70-9ff3-af8702ce4750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cache Pipeline steps to reduce execution time on subsequent executions\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")\n",
    "preloader_instance_count = ParameterInteger(name=\"PreLoaderInstanceCount\", default_value=1)\n",
    "preloader_instance_type = ParameterString(name=\"PreLoaderInstanceType\", default_value=\"ml.m5.large\")\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.c5.xlarge\")\n",
    "transform_instance_count = ParameterInteger(name=\"TransformInstanceCount\", default_value=1)\n",
    "transform_instance_type = ParameterString(name=\"TransformInstanceType\", default_value=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734825d4-3cda-4733-80f7-bee5b68e470b",
   "metadata": {},
   "source": [
    "### Configure Preloader step\n",
    "Here we will create a preloader step. We will use a egenric SageMaker estimator and provide the custom docker image we built for this. Instance type parameters createed above will be added to the estimator as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620152c4-8857-4bcc-b21a-6ab708dc38fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preloader_job_name = f\"fsx-demo-preloader-{int(time.time())}\"\n",
    "preloader = sagemaker.estimator.Estimator(\n",
    "    image_uri=preloader_image,\n",
    "    role=role, \n",
    "    instance_type=preloader_instance_type,\n",
    "    instance_count=preloader_instance_count,\n",
    "    volume_size = 100,\n",
    "    sagemaker_session=pipeline_session, \n",
    "    subnets=subnets,\n",
    "    security_group_ids=security_group_ids\n",
    ")\n",
    "\n",
    "preloader_args = preloader.fit(inputs=data_channels, job_name=preloader_job_name, logs='All', wait=True)\n",
    "step_preloader = TrainingStep(\n",
    "    name='PreLoad-FSX',\n",
    "    step_args=preloader_args,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdae87-5c45-4ca8-95af-e30d6e562792",
   "metadata": {},
   "source": [
    "### Configure Training Step\n",
    "In this step we will create a PyTorch estimator with an entry point and create a training step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503a241-b60f-4b70-a338-92ae8cde4d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_job_name = f\"fsx-demo-training-{int(time.time())}\"\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"cifar10.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=training_instance_count,\n",
    "    instance_type=training_instance_type,\n",
    "    sagemaker_session=pipeline_session, \n",
    "    subnets=subnets,\n",
    "    security_group_ids=security_group_ids\n",
    "\n",
    ")\n",
    "\n",
    "train_args = estimator.fit(inputs=data_channels, job_name=estimator_job_name, logs='All', wait=True)\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name='TrainCNNModel',\n",
    "    step_args=train_args,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca520be8-8457-4a1c-80a2-cff7cdccc8e6",
   "metadata": {},
   "source": [
    "### Create Model Step\n",
    "This creates a PyTorch model with model create step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845e77a-ca4f-46f6-92c8-86cd1975bd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"fsx-demo-CNNModel\"\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    "    entry_point=\"cifar10.py\",\n",
    "    name=model_name,\n",
    "    framework_version=\"1.8.0\",\n",
    "    py_version=\"py3\",\n",
    "\n",
    ")\n",
    "\n",
    "step_model_create = ModelStep(\n",
    "    name=\"ModelCreationStep\",\n",
    "    step_args=pytorch_model.create(instance_type=\"ml.c5.xlarge\"),\n",
    "    display_name=model_name, \n",
    "    description=\"Model to predict cifar data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cba41-fd4f-4ff9-8603-b41f39ab4cb2",
   "metadata": {},
   "source": [
    "### Create Transformer Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310cc51-510e-47ba-9876-8e8196b84917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_model_create.properties.ModelName,\n",
    "    instance_type=transform_instance_type,\n",
    "    instance_count=transform_instance_count,\n",
    "    output_path=inreference_output,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "transform_args = transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"Transform\", step_args=transform_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020428f5-1fdf-40ee-9abf-425edbaed654",
   "metadata": {},
   "source": [
    "### Configure SM Pipeline\n",
    "\n",
    "We will add dependencies for the steps, parameters to the pipeline and create the pipeline defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979f920-93d7-4ce9-a8a9-a93814402db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_train.add_depends_on([step_preloader])\n",
    "#step_model_create.add_depends_on([step_train])\n",
    "step_transform.add_depends_on([step_model_create])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c65b0-7853-4e66-936d-588a262f20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "pipeline_name = \"SageMaker-FSx-Lambda-pipeline\" + current_time\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        preloader_instance_count,\n",
    "        preloader_instance_type,\n",
    "        training_instance_count,\n",
    "        training_instance_type,\n",
    "        transform_instance_count,\n",
    "        transform_instance_type\n",
    "    ],\n",
    "    steps=[step_preloader,step_train,step_model_create,step_transform],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4bf55-87e2-452e-87f6-b368bc4b57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33aa921-bcac-45fd-a1d0-b5317e130ebd",
   "metadata": {},
   "source": [
    "### Create the Pipeline and run\n",
    "\n",
    "We will create the pipeline with the definition created above and start an instance of the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0a257-d7e3-4f65-9f6a-6dbe9270eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb6545-d40c-4e73-b69b-3be6a41c8526",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fa9c0-4d4d-40e5-b311-bb3b2ed639a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e1c55-ec48-4303-8cda-8a31906b31a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bc721-b650-4b1f-b314-c0926c784c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
